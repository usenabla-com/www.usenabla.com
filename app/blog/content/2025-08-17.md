---
title: "In the era of extraction, be a curator"
summary: "It's easy to strip mine the web for content, but have we ever thought about a class of people who carefully curate data while respecting the work put into building the web?"
author: "James Bohrman"
published: "2025-07-08"
image: "https://github.com/Atelier-Logos/www.atelierlogos.studio/blob/main/public/extraction.png?raw=true"
tags: ["Ecosystems", "Software"]
---

## The internet is great, don't muck it up

I love the internet. I remember when I was a kid begging my parents to get high speed internet so I could play some obscure game that was an MMO back in the early 2000s. 

Back then, there was no concept of ethics or even any idea of the crazy new realities that the next two decades would bring. Still, even with all the chaos, I'm happy the internet exists. 

I also personally do not like seeing the content of the people who create the internet, the small creators, and those who are just trying to create fun content have their material strip mined to fuel the capitalistic and technofascist greed of goons at foundation model companies who believe they have full rights to the entire internet. 

## The internet was built on a unspoken social contract

The web as it was originally built was a simple one. It assumed a few key things:

- Open Sharing in Exchange for Fair Use
- Human Readability Assumption
- Robots.txt as a Boundary Marker

> Almost 30 years ago, two Stanford grad students, Larry Page and Sergey Brin, built Google on a simple bargain: content creators would let them copy the entire web in exchange for traffic. For years, that traffic powered ad revenue, subscriptions, and the growth of online media. Google mostly upheld its end of the deal. But that era is collapsing under the weight of AI.

Today, this social contract has been largely breached as companies bypass `robots.txt` and declare open war on any concept of reciprocity.

This is why I'm exited to see new efforts to put the internet back in the hands of the creators with things like [Cloudflares policy shift](https://gizmodo.com/free-lunch-is-over-for-the-ai-that-broke-the-web-2000623837) to blocking AI crawlers from scraping sites hosted on its platform unless those bots pay content creators for the data they consume. 

## The curators stand to win big

So we're at a point where the biggest infrastructure provider is talking about locking down the web to bots, so what do you do if you're a AI model company or building a tool in that space? 

I'm not sure I agree with the idea [Forbes](https://www.forbes.com/sites/johnwerner/2024/11/04/running-out-of-data-it-could-be-a-concern/) laid out here personally, because the idea of "running out of data" seem preposterous to me unless they are considering the internet to be just one big blob of unstructured data. 

Which in some ways **it is**, but that's also why you can't ever run out of data. For example, Ferropipe at it's core is just a JSON feed of crates.io data, but when you enrich the data with new info it becomes something totally different. Data can change shape, form, and use case so many times that the idea of running out doesn't make sense. So what I'm getting at is that the people who can curate, and prepare the data for LLM tools efficiently while respecting the changing ecosystem, stand to win big in the new era.

## Conclusion

That's my thoughts on where we are, and where we are going. I'm not sure if any of it will ring true or if we'll just end up in a tech dystopia like everytone seems to think. Who knows. What I do know, is that if you have a need for quality Rust crate data, you should check out [Ferropipe](https://www.atelierlogos.studio/ferropipe) and get an API key. Besides that, I'm just a delusional tech worker trying to not starve. 